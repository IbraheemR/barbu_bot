{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 13:58:52,150\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.6</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.6', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', address_info={'node_ip_address': '138.38.233.129', 'raylet_ip_address': '138.38.233.129', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-16_13-58-50_660514_267027/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-16_13-58-50_660514_267027/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-10-16_13-58-50_660514_267027', 'metrics_export_port': 60730, 'gcs_address': '138.38.233.129:43558', 'address': '138.38.233.129:43558', 'dashboard_agent_listen_port': 52365, 'node_id': 'c03d1fd8f6a2d8919169f10d8ba39aeb877ce718bd33eeacc385cb1e'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.examples.policy.random_policy import RandomPolicy\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from barbu_env import BarbuMultiAgentEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_env(\"barbu_reds\", lambda _: BarbuMultiAgentEnv())\n",
    "\n",
    "config = {\n",
    "    \"env\": \"barbu_reds\",\n",
    "    \"env_config\": {\n",
    "        \"num_agents\": 4,\n",
    "    },\n",
    "    \"num_workers\": 2,\n",
    "    \"num_gpus\": 1,\n",
    "\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            \"ppo\": (None, BarbuMultiAgentEnv.observation_space, BarbuMultiAgentEnv.action_space, {}),\n",
    "            \"random\": (RandomPolicy, BarbuMultiAgentEnv.observation_space, BarbuMultiAgentEnv.action_space, {}),\n",
    "        },\n",
    "        \"policy_mapping_fn\": lambda agent_id: \"ppo\"\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "results = tune.Tuner(\"PPO\", param_space=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-10-16 13:58:58 (running for 00:00:05.80)<br>Memory usage on this node: 6.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/6.44 GiB heap, 0.0/3.22 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/ibraheem/ray_results/PPO<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_barbu_reds_49456_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_barbu_reds_49456_00000</td><td style=\"text-align: right;\">           1</td><td>/home/ibraheem/ray_results/PPO/PPO_barbu_reds_49456_00000_0_2022-10-16_13-58-53/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/util/placement_group.py:80: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  ).remote(self)\n",
      "/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "  warnings.warn(\n",
      "/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/actor.py:637: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_bundle_index parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/actor.py:637: DeprecationWarning: placement_group_capture_child_tasks parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/releases-2.0.0/ray-core/package-ref.html#ray-remote.\n",
      "  return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m bash: /home/ibraheem/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m 2022-10-16 13:58:56,089\tINFO algorithm.py:1871 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m 2022-10-16 13:58:56,091\tINFO algorithm.py:351 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m /home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/_private/ray_option_utils.py:266: DeprecationWarning: Setting 'object_store_memory' for actors is deprecated since it doesn't actually reserve the required object store memory. Use object spilling that's enabled by default (https://docs.ray.io/en/releases-2.0.0/ray-core/objects/object-spilling.html) instead to bypass the object store memory size limitation.\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m bash: /home/ibraheem/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m bash: /home/ibraheem/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "2022-10-16 13:58:58,835\tERROR trial_runner.py:980 -- Trial PPO_barbu_reds_49456_00000: Error processing event.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 989, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/_private/worker.py\", line 2277, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=286136, ip=138.38.233.129, repr=PPO)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 125, in __init__\n",
      "    self.add_workers(\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 269, in add_workers\n",
      "    self.foreach_worker(lambda w: w.assert_healthy())\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 391, in foreach_worker\n",
      "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "    next_obs, reward, done, info = env.step(sampled_action)\n",
      "  File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "    raise Exception(action)\n",
      "Exception: {}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 495, in __init__\n",
      "    check_env(self.env)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 83, in check_env\n",
      "    raise ValueError(\n",
      "ValueError: Traceback (most recent call last):\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "    check_multiagent_environments(env)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "    next_obs, reward, done, info = env.step(sampled_action)\n",
      "  File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "    raise Exception(action)\n",
      "Exception: {}\n",
      "\n",
      "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::PPO.__init__()\u001b[39m (pid=286136, ip=138.38.233.129, repr=PPO)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 308, in __init__\n",
      "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 157, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 443, in setup\n",
      "    raise e.args[0].args[2]\n",
      "ValueError: Traceback (most recent call last):\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "    check_multiagent_environments(env)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "    next_obs, reward, done, info = env.step(sampled_action)\n",
      "  File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "    raise Exception(action)\n",
      "Exception: {}\n",
      "\n",
      "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_barbu_reds_49456_00000:\n",
      "  trial_id: '49456_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m 2022-10-16 13:58:58,783\tERROR worker.py:756 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=286136, ip=138.38.233.129, repr=PPO)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 125, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     self.add_workers(\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 269, in add_workers\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     self.foreach_worker(lambda w: w.assert_healthy())\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 391, in foreach_worker\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     next_obs, reward, done, info = env.step(sampled_action)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     raise Exception(action)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m Exception: {}\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 495, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     check_env(self.env)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 83, in check_env\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     raise ValueError(\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m ValueError: Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     check_multiagent_environments(env)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     next_obs, reward, done, info = env.step(sampled_action)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     raise Exception(action)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m Exception: {}\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \u001b[36mray::PPO.__init__()\u001b[39m (pid=286136, ip=138.38.233.129, repr=PPO)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 308, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 157, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 443, in setup\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     raise e.args[0].args[2]\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m ValueError: Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     check_multiagent_environments(env)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     next_obs, reward, done, info = env.step(sampled_action)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m   File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m     raise Exception(action)\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m Exception: {}\n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=286136)\u001b[0m The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m 2022-10-16 13:58:58,828\tWARNING multi_agent_env.py:151 -- observation_space_contains() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m 2022-10-16 13:58:58,828\tWARNING multi_agent_env.py:151 -- observation_space_contains() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m 2022-10-16 13:58:58,828\tWARNING multi_agent_env.py:151 -- observation_space_contains() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m 2022-10-16 13:58:58,828\tWARNING multi_agent_env.py:207 -- action_space_sample() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m 2022-10-16 13:58:58,829\tERROR worker.py:756 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286165, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f910f5e8460>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m     next_obs, reward, done, info = env.step(sampled_action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m   File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m     raise Exception(action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m Exception: {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286165, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f910f5e8460>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 495, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m     check_env(self.env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 83, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m     raise ValueError(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m ValueError: Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m     check_multiagent_environments(env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m     next_obs, reward, done, info = env.step(sampled_action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m   File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m     raise Exception(action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m Exception: {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286165)\u001b[0m The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m 2022-10-16 13:58:58,778\tWARNING multi_agent_env.py:239 -- observation_space_sample() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m 2022-10-16 13:58:58,778\tWARNING multi_agent_env.py:151 -- observation_space_contains() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m 2022-10-16 13:58:58,778\tWARNING multi_agent_env.py:151 -- observation_space_contains() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m 2022-10-16 13:58:58,778\tWARNING multi_agent_env.py:151 -- observation_space_contains() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m 2022-10-16 13:58:58,778\tWARNING multi_agent_env.py:207 -- action_space_sample() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m 2022-10-16 13:58:58,778\tWARNING multi_agent_env.py:175 -- action_space_contains() has not been implemented\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m 2022-10-16 13:58:58,779\tERROR worker.py:756 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m     next_obs, reward, done, info = env.step(sampled_action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m   File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m     raise Exception(action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m Exception: {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 495, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m     check_env(self.env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 83, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m     raise ValueError(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m ValueError: Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m     check_multiagent_environments(env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m   File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m     next_obs, reward, done, info = env.step(sampled_action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m   File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m     raise Exception(action)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m Exception: {}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=286164)\u001b[0m The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "2022-10-16 13:58:58,844\tERROR ray_trial_executor.py:103 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 94, in _post_stop_cleanup\n",
      "    ray.get(future, timeout=0)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/_private/worker.py\", line 2277, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=286136, ip=138.38.233.129, repr=PPO)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 125, in __init__\n",
      "    self.add_workers(\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 269, in add_workers\n",
      "    self.foreach_worker(lambda w: w.assert_healthy())\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 391, in foreach_worker\n",
      "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "    next_obs, reward, done, info = env.step(sampled_action)\n",
      "  File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "    raise Exception(action)\n",
      "Exception: {}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=286164, ip=138.38.233.129, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f638963c4c0>)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 495, in __init__\n",
      "    check_env(self.env)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 83, in check_env\n",
      "    raise ValueError(\n",
      "ValueError: Traceback (most recent call last):\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "    check_multiagent_environments(env)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "    next_obs, reward, done, info = env.step(sampled_action)\n",
      "  File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "    raise Exception(action)\n",
      "Exception: {}\n",
      "\n",
      "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::PPO.__init__()\u001b[39m (pid=286136, ip=138.38.233.129, repr=PPO)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 308, in __init__\n",
      "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 157, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 443, in setup\n",
      "    raise e.args[0].args[2]\n",
      "ValueError: Traceback (most recent call last):\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 70, in check_env\n",
      "    check_multiagent_environments(env)\n",
      "  File \"/home/ibraheem/miniconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/pre_checks/env.py\", line 287, in check_multiagent_environments\n",
      "    next_obs, reward, done, info = env.step(sampled_action)\n",
      "  File \"/home/ibraheem/Desktop/barbu_bot/barbu_env.py\", line 59, in step\n",
      "    raise Exception(action)\n",
      "Exception: {}\n",
      "\n",
      "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\n",
      "2022-10-16 13:58:58,946\tERROR tune.py:754 -- Trials did not complete: [PPO_barbu_reds_49456_00000]\n",
      "2022-10-16 13:58:58,947\tINFO tune.py:758 -- Total run time: 5.92 seconds (5.80 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x7faec066e1d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rllib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct  7 2022, 20:19:58) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4696ef454f56e1321b5473c6d4b0148f4af87412dc47138694c27d2793afd11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
